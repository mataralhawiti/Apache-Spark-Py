{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Standalone Spark Cluster :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start the master\n",
    "In new cmd run :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-class org.apache.spark.deploy.master.Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019-04-22 09:21:01 INFO  Utils:54 - Successfully started service 'sparkMaster' on port 7077. <br>\n",
    "2019-04-22 09:21:02 INFO  Master:54 - Starting Spark master at spark://172.25.100.113:7077\n",
    "<br>\n",
    "the master now is working on :\n",
    "172.25.100.113:7077 (http://localhost:8080/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the worker node\n",
    "In new cmd run ( please replace **IP:PORT** with the correct ones from previous step outpu ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-class org.apache.spark.deploy.worker.Worker spark://IP:PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully started service 'sparkWorker' on port 53326 <br>\n",
    "the worker now is working on :<br>\n",
    "172.25.100.113:53326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start Spark History server\n",
    "In new cmd run :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-class org.apache.spark.deploy.history.HistoryServer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before you start history server :\n",
    "1. Create a new folder to hold log files (**C:\\tmp\\spark-events**)\n",
    "\n",
    "2. in **C:\\Spark\\spark-2.3.3-bin-hadoop2.7\\conf**, make a copy of (spark-defaults.conf.template) and then rename it to (spark-defaults.conf) with the following options :\n",
    "        # Example:\n",
    "        # spark.master                     spark://master:7077\n",
    "        spark.eventLog.enabled           true\n",
    "        spark.eventLog.dir               file:/tmp/spark-events\n",
    "        # spark.serializer                 org.apache.spark.serializer.KryoSerializer\n",
    "        # spark.driver.memory              5g\n",
    "        # spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
